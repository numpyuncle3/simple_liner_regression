{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "#这是一个线性回归的例子，也没有用到tensorflow啊，学习一下，很easy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.0108365   -2.85487576]\n",
      " [ -9.66418324 -14.34769176]\n",
      " [ -4.91858516  -7.22031834]\n",
      " [ -9.16697901 -13.44517812]\n",
      " [ -6.89409202  -9.94698719]\n",
      " [  4.70970618   7.13233692]\n",
      " [ -9.93474113 -14.68263039]\n",
      " [ -9.70573537 -14.26223845]\n",
      " [  5.2020093    7.73358919]\n",
      " [  6.48844671   9.55940342]\n",
      " [ -2.19310591  -3.15213386]\n",
      " [ -4.09434802  -6.06965762]\n",
      " [ -8.39282764 -12.18957917]\n",
      " [  3.99901384   6.1086301 ]\n",
      " [ -6.47403476  -9.51560221]\n",
      " [  5.17075887   7.71167099]\n",
      " [  7.01446219  10.54298205]\n",
      " [  7.86628245  11.83245222]\n",
      " [  9.11718018  13.62786629]\n",
      " [ -7.47459978 -11.14578359]\n",
      " [ -0.50320375  -0.62343534]\n",
      " [  0.59901139   1.08945006]\n",
      " [ -9.41947783 -13.80400128]\n",
      " [  8.06846068  12.04554883]\n",
      " [ -4.16321024  -6.04894513]\n",
      " [ -1.29551966  -1.61212937]\n",
      " [ -5.54626421  -8.09364911]\n",
      " [ -2.61371397  -3.77964359]\n",
      " [  6.43770375   9.69953534]\n",
      " [ -0.76838962  -1.04803717]\n",
      " [  3.73742607   5.62375248]\n",
      " [ -1.73309219  -2.58958571]\n",
      " [ -0.22847523  -0.29705202]\n",
      " [  5.33636917   8.091904  ]\n",
      " [  3.30027687   5.1760758 ]\n",
      " [  1.54239522   2.49034749]\n",
      " [  8.46435125  12.72226898]\n",
      " [  0.97533206   1.59544453]\n",
      " [  4.7348735    7.28004909]\n",
      " [ -4.21350639  -6.08385533]\n",
      " [ -5.52922869  -8.08560706]\n",
      " [  6.29972174   9.50291796]\n",
      " [ -5.92532912  -8.54676972]\n",
      " [ -1.6574232   -2.43940426]\n",
      " [  4.62151805   7.00228352]\n",
      " [ -1.10456407  -1.51758799]\n",
      " [  9.81979475  14.70276867]\n",
      " [  8.75114069  13.09612019]\n",
      " [  8.74294871  13.13978607]\n",
      " [  6.81394619   9.93467869]\n",
      " [ -3.92888933  -5.63950153]\n",
      " [  3.75897887   5.62953616]\n",
      " [  8.08075437  11.95374765]\n",
      " [ -3.51058141  -4.98811465]\n",
      " [ -1.27793195  -1.68156835]\n",
      " [  7.65650218  11.43502802]\n",
      " [  3.56990161   5.41729807]\n",
      " [ -4.23913463  -6.24922611]\n",
      " [  9.54723011  14.16763114]\n",
      " [ -9.26338318 -13.64944604]\n",
      " [ -6.69992324  -9.76977161]\n",
      " [ -8.23434995 -12.13875789]\n",
      " [  7.40644376  11.21851313]\n",
      " [  7.9389874   11.74852514]\n",
      " [ -0.55117822  -0.81504844]\n",
      " [  8.3580522   12.40884499]\n",
      " [ -3.29425436  -4.77146037]\n",
      " [  3.53364249   5.20588603]\n",
      " [  1.00241758   1.74998544]\n",
      " [  3.88120819   5.75390214]\n",
      " [  0.5780685    0.92388055]\n",
      " [ -4.35778389  -6.42899816]\n",
      " [  8.97340393  13.39813278]\n",
      " [  1.03663217   1.61261274]\n",
      " [ -8.6431632  -12.599729  ]\n",
      " [  1.6616852    2.300435  ]\n",
      " [ -1.57666485  -2.08693751]\n",
      " [  2.99609557   4.59811395]\n",
      " [ -5.24138718  -7.47470461]\n",
      " [ -3.89574148  -5.74137997]\n",
      " [ -3.13568196  -4.55153892]\n",
      " [  0.15119743   0.47889753]\n",
      " [ -9.89809397 -14.57601544]\n",
      " [ -2.45072964  -3.5339691 ]\n",
      " [  5.84363123   8.79100791]\n",
      " [ -0.60199969  -0.80881949]\n",
      " [  2.50621016   3.99971134]\n",
      " [ -9.79091571 -14.47078369]\n",
      " [ -5.19457694  -7.57152121]\n",
      " [ -8.41834408 -12.50170755]\n",
      " [ -4.09862705  -6.02958123]\n",
      " [ -4.54635524  -6.61299139]\n",
      " [  9.27121397  13.75849887]\n",
      " [ -0.29833097  -0.44833243]\n",
      " [  7.63479708  11.34548147]\n",
      " [  4.95462968   7.19138113]\n",
      " [ -0.5350333   -0.75787467]\n",
      " [ -6.57105303  -9.6957168 ]\n",
      " [ -0.5861508   -0.71146554]\n",
      " [  2.52702311   3.97793256]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(100):\n",
    "    x = np.random.uniform(-10.,10.)#均匀分布的x\n",
    "    eps = np.random.normal(0.,0.1)\n",
    "    y = 1.477 * x + 0.089 + eps\n",
    "    data.append([x,y])\n",
    "data = np.array(data)\n",
    "print(data)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数用以求损失\n",
    "def mse(w,b,points):\n",
    "    totalerror = 0.\n",
    "    for i in range(len(points)):\n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        error = ((w * x +b)-y) ** 2\n",
    "        totalerror = totalerror + error\n",
    "    return totalerror/float(len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数用以更新w和b\n",
    "def step_gradient(w_current,b_current,points,lr):\n",
    "    w_grad = 0\n",
    "    b_grad = 0\n",
    "    m = float(len(points))\n",
    "    for i in range(len(points)):\n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        w_grad = w_grad + x *((w_current*x+b_current)-y)\n",
    "        b_grad = b_grad + ((w_current*x+b_current)-y)\n",
    "       \n",
    "    w_new = w_current - w_grad*(2/m)*lr\n",
    "    b_new = b_current - b_grad*(2/m)*lr\n",
    "    \n",
    "    return w_new,b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数用以进行n次迭代\n",
    "def gradient_descent(points,w_start,b_start,lr,num_iterations):\n",
    "    w = w_start\n",
    "    b = b_start\n",
    "    for step in range(num_iterations):\n",
    "        w,b = step_gradient(w,b,np.array(points),lr)\n",
    "        loss = mse(w,b,points)\n",
    "        if step%50 == 0:\n",
    "            print('step = ',step,' loss = ',loss,' w = ',w,' b = ',b)\n",
    "    return w,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0  loss =  7.893516238401191  w =  0.9978203524227581  b =  0.0033599010806757176\n",
      "step =  50  loss =  0.011014983108394471  w =  1.481239322767893  b =  0.06855826753709125\n",
      "step =  100  loss =  0.009828385078660134  w =  1.4812089825648826  b =  0.09207568136586337\n",
      "step =  150  loss =  0.009671001505454387  w =  1.4811979329695926  b =  0.10064048579348388\n",
      "step =  200  loss =  0.00965012704881927  w =  1.4811939088186654  b =  0.10375970100215792\n",
      "step =  250  loss =  0.009647358380330347  w =  1.4811924432635695  b =  0.10489568765547211\n",
      "step =  300  loss =  0.00964699115998367  w =  1.4811919095232158  b =  0.10530940251327343\n",
      "step =  350  loss =  0.009646942453978046  w =  1.4811917151403735  b =  0.10546007328309819\n",
      "step =  400  loss =  0.00964693599389215  w =  1.481191644348107  b =  0.10551494605464964\n",
      "step =  450  loss =  0.009646935137063332  w =  1.481191618566279  b =  0.10553493016345349\n",
      "step =  500  loss =  0.009646935023418457  w =  1.4811916091767978  b =  0.10554220817390189\n",
      "step =  550  loss =  0.00964693500834523  w =  1.4811916057572436  b =  0.10554485875174893\n",
      "step =  600  loss =  0.009646935006346016  w =  1.4811916045118765  b =  0.10554582406541156\n",
      "step =  650  loss =  0.009646935006080857  w =  1.4811916040583264  b =  0.10554617562289118\n",
      "step =  700  loss =  0.00964693500604569  w =  1.481191603893148  b =  0.10554630365657208\n",
      "step =  750  loss =  0.009646935006041031  w =  1.4811916038329918  b =  0.1055463502851446\n",
      "step =  800  loss =  0.009646935006040405  w =  1.4811916038110835  b =  0.10554636726679945\n",
      "step =  850  loss =  0.009646935006040337  w =  1.4811916038031048  b =  0.10554637345134653\n",
      "step =  900  loss =  0.00964693500604032  w =  1.4811916038001989  b =  0.10554637570369604\n",
      "step =  950  loss =  0.009646935006040315  w =  1.4811916037991406  b =  0.10554637652397905\n"
     ]
    }
   ],
   "source": [
    "#主程序\n",
    "lr = 0.01\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "num_iterations = 1000\n",
    "w_final , b_final  = gradient_descent(data, w_init, b_init, lr, num_iterations)\n",
    "loss_final = mse(w_final , b_final, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  1.4811916037987598 b =  0.10554637681922581\n"
     ]
    }
   ],
   "source": [
    "print('w = ',w_final,'b = ',b_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
